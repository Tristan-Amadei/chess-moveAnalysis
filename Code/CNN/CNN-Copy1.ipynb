{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63691d6-e72f-49ea-9840-74ac8ac6cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install chess\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275661f0-d82b-4989-b5a9-9b7b0bb1657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import time\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "import chess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd355cc9-fcff-428a-98dc-4fb0244048c8",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6475230d-bcf5-44bb-95fd-e3a3213b5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CNN/S3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511d03d8-42d9-4ff7-ad96-31a49f43b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moves_df = pd.read_csv(\"../Data/moves_df.csv\")\n",
    "moves_df = open_csv(\"moves_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f911d60-9dac-4ee9-b598-1bc8b7789fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_index</th>\n",
       "      <th>moves</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>fen</th>\n",
       "      <th>zobrist_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e2e4</td>\n",
       "      <td>35</td>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>9384546495678726550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>e7e5</td>\n",
       "      <td>48</td>\n",
       "      <td>rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>595762792459712928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>g1f3</td>\n",
       "      <td>111</td>\n",
       "      <td>rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQK...</td>\n",
       "      <td>15213300192948443293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b8c6</td>\n",
       "      <td>47</td>\n",
       "      <td>r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNB...</td>\n",
       "      <td>8704797333742910878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>f1b5</td>\n",
       "      <td>52</td>\n",
       "      <td>r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/R...</td>\n",
       "      <td>5409798013178080797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023518</th>\n",
       "      <td>118318</td>\n",
       "      <td>a8c8</td>\n",
       "      <td>-6</td>\n",
       "      <td>2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP1BP1/1P1BPP1P...</td>\n",
       "      <td>13935396515866781493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023519</th>\n",
       "      <td>118318</td>\n",
       "      <td>f3g2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP2P1/1P1BPPBP/...</td>\n",
       "      <td>18028698229637126573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023520</th>\n",
       "      <td>118318</td>\n",
       "      <td>a7a6</td>\n",
       "      <td>12</td>\n",
       "      <td>2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...</td>\n",
       "      <td>2937820813377462641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023521</th>\n",
       "      <td>118318</td>\n",
       "      <td>a1c1</td>\n",
       "      <td>25</td>\n",
       "      <td>2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...</td>\n",
       "      <td>11978245410268853311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023522</th>\n",
       "      <td>118318</td>\n",
       "      <td>b7b5</td>\n",
       "      <td>5</td>\n",
       "      <td>2rq1rk1/4bppp/p1n1pn2/1p1p4/8/P1NP2P1/1P1BPPBP...</td>\n",
       "      <td>14285185648144582914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9023523 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         game_index moves  evaluation  \\\n",
       "0                 0  e2e4          35   \n",
       "1                 0  e7e5          48   \n",
       "2                 0  g1f3         111   \n",
       "3                 0  b8c6          47   \n",
       "4                 0  f1b5          52   \n",
       "...             ...   ...         ...   \n",
       "9023518      118318  a8c8          -6   \n",
       "9023519      118318  f3g2          -2   \n",
       "9023520      118318  a7a6          12   \n",
       "9023521      118318  a1c1          25   \n",
       "9023522      118318  b7b5           5   \n",
       "\n",
       "                                                       fen  \\\n",
       "0        rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...   \n",
       "1        rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...   \n",
       "2        rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQK...   \n",
       "3        r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNB...   \n",
       "4        r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/R...   \n",
       "...                                                    ...   \n",
       "9023518  2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP1BP1/1P1BPP1P...   \n",
       "9023519  2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP2P1/1P1BPPBP/...   \n",
       "9023520  2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...   \n",
       "9023521  2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...   \n",
       "9023522  2rq1rk1/4bppp/p1n1pn2/1p1p4/8/P1NP2P1/1P1BPPBP...   \n",
       "\n",
       "                  zobrist_key  \n",
       "0         9384546495678726550  \n",
       "1          595762792459712928  \n",
       "2        15213300192948443293  \n",
       "3         8704797333742910878  \n",
       "4         5409798013178080797  \n",
       "...                       ...  \n",
       "9023518  13935396515866781493  \n",
       "9023519  18028698229637126573  \n",
       "9023520   2937820813377462641  \n",
       "9023521  11978245410268853311  \n",
       "9023522  14285185648144582914  \n",
       "\n",
       "[9023523 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bdda4-5217-4bde-91e4-f31eb3b6e6b4",
   "metadata": {},
   "source": [
    "# Create board representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec23eda-59da-4a2d-b295-147e97620fab",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e466f8a-1439-403a-8e42-f407f00260b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CNN/board_representation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bdf34e-2bda-4485-b4ae-8b649ecf17f6",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be169f2a-34d2-49d4-9f8f-924ff3466fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb2b509-468b-4217-80ac-3bc2f9a57378",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cpu_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1506b84-5bed-4a6a-b63e-5403c4325689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we'll divide the fens into the nb of cpu cores we have, to use parallelize the creation of board representations\n",
    "\n",
    "def get_starting_indices(len_data, divide_into):\n",
    "    linspace = np.linspace(0, len_data, divide_into)\n",
    "    indices = [math.floor(x) for x in linspace]\n",
    "    return indices    \n",
    "\n",
    "def get_lengths(len_data, indices):\n",
    "    if len(indices) <= 1:\n",
    "        return [len_data]\n",
    "    lengths = [indices[1]]\n",
    "    for i in range(2, len(indices)):\n",
    "        lengths.append(indices[i]-indices[i-1])\n",
    "    lengths.append(len_data-indices[-1])\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e583c665-92c0-4e27-adaf-2456ff026a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_representations__subpart(all_fens, starting_index, length):\n",
    "    fens = all_fens[starting_index:starting_index+length]\n",
    "    X = np.zeros((len(fens), 8, 8, NB_OHE), dtype = np.uint8)\n",
    "    for i, fen in enumerate(fens):\n",
    "        X[i] = fen_to_matrix(fen)\n",
    "    return X\n",
    "\n",
    "def get_matrix_representations(df, total_size, divide_into=nb_cpu_cores):\n",
    "    X = np.zeros((total_size, 8, 8, NB_OHE), dtype = np.uint8)\n",
    "    fens = list(df.iloc[:total_size].fen)\n",
    "    \n",
    "    starting_indices = get_starting_indices(total_size, divide_into)\n",
    "    lengths = get_lengths(total_size, starting_indices)\n",
    "\n",
    "    with Pool() as pool:\n",
    "        async_results = [pool.apply_async(get_matrix_representations__subpart,\n",
    "                                        args = (fens.copy(), starting_indices[i], lengths[i])) for i in range(len(lengths))]\n",
    "\n",
    "        for i in range(len(async_results)):\n",
    "            start_index, length = starting_indices[i], lengths[i]\n",
    "            #sub_X = async_results[i].get()\n",
    "            X[start_index:start_index+length] = async_results[i].get()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b66e834f-563f-447a-ba03-a19ccae9aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 2_000_000\n",
    "#total_size = len(moves_df)\n",
    "fens = list(moves_df.fen)[:total_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62740399-e350-493f-b33a-41914a59cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating X took 1.0m, 5.048561096191406s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    X = get_matrix_representations(moves_df, total_size, divide_into=nb_cpu_cores)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Creating X took {(stop-start)//60}m, {(stop-start)%60}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c96745-9aed-41cf-9e90-a670cc648f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X takes up 0.23% of total memory\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import sys\n",
    "    \n",
    "total_memory = psutil.virtual_memory().total \n",
    "X_size = sys.getsizeof(X)\n",
    "print(f\"X takes up {round(100 * X_size/total_memory, 2)}% of total memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8e157-816c-4ca7-8247-c3fc3207c7c7",
   "metadata": {},
   "source": [
    "### Split into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c40fd9-73ce-4c9c-a372-0a39ae6fce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(moves_df.iloc[:total_size].evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18ddab86-d199-4731-b2e5-eab0f14cf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test(dataX, dataY, train_ratio=0.75, validation_ratio=0.15, test_ratio=0.10):\n",
    "    if train_ratio+test_ratio+validation_ratio != 1:\n",
    "        print(\"Ratios do not add up to 1\")\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "        return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02998c37-744a-4e29-82e6-a63e367ca6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4f35d32-853a-4152-9b42-f1645efd9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape : X_train -> (1500000, 8, 8, 12), y_train -> (1500000,)\n",
      "Validation set shape : X_val -> (300000, 8, 8, 12), y_val -> (300000,)\n",
      "Test set shape : X_test -> (200000, 8, 8, 12), y_train -> (200000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape : X_train -> {X_train.shape}, y_train -> {y_train.shape}\")\n",
    "print(f\"Validation set shape : X_val -> {X_val.shape}, y_val -> {y_val.shape}\")\n",
    "print(f\"Test set shape : X_test -> {X_test.shape}, y_train -> {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdde28-8cfa-48b6-b46a-7ce170059de0",
   "metadata": {},
   "source": [
    "# Try Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcb33da9-763b-44de-9e96-8ccb428bab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.12.0\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #remove warnings caused by tensorflow\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b16cbf0-53ad-422d-9c87-5a00b7bf30a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(1e-4), \n",
    "                        input_shape=(8, 8, NB_OHE)))\n",
    "    \n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(1e-4), \n",
    "                       ))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128, activation='relu',\n",
    "         kernel_regularizer=regularizers.l1(1e-4),\n",
    "         ))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1024, activation='elu',\n",
    "         #kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "          kernel_regularizer=regularizers.l1(1e-4),\n",
    "         ))\n",
    "\n",
    "model.add(layers.Dropout(0.6))\n",
    "\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3e79383-cdfd-469b-b924-b469c639119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          3488      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 6, 6, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              132096    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,689\n",
      "Trainable params: 286,497\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "085f1493-f214-4732-8015-68fb96bd8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-2\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "          #optimizer=tf.keras.optimizers.Adam(\n",
    "              #learning_rate=lr_schedule\n",
    "              #learning_rate = 1e-3\n",
    "          #),\n",
    "          optimizer = tf.keras.optimizers.Adadelta(),\n",
    "          metrics=[RSquare()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0b5dd5b-1f6f-4452-95b9-c7c69941d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "callbacks = [\n",
    "            es,\n",
    "            checkpoint,\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e023dc-50ce-4106-bf1b-cbb5c33daa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5857/5860 [============================>.] - ETA: 0s - loss: 190381.1562 - r_square: -0.0232\n",
      "Epoch 1: val_loss improved from inf to 184560.04688, saving model to model.h5\n",
      "5860/5860 [==============================] - 52s 8ms/step - loss: 190380.0000 - r_square: -0.0232 - val_loss: 184560.0469 - val_r_square: -0.0211\n",
      "Epoch 2/1000\n",
      "5860/5860 [==============================] - ETA: 0s - loss: 189302.0469 - r_square: -0.0174\n",
      "Epoch 2: val_loss improved from 184560.04688 to 183398.09375, saving model to model.h5\n",
      "5860/5860 [==============================] - 50s 8ms/step - loss: 189302.0469 - r_square: -0.0174 - val_loss: 183398.0938 - val_r_square: -0.0147\n",
      "Epoch 3/1000\n",
      "5860/5860 [==============================] - ETA: 0s - loss: 188265.0781 - r_square: -0.0118\n",
      "Epoch 3: val_loss improved from 183398.09375 to 182459.92188, saving model to model.h5\n",
      "5860/5860 [==============================] - 49s 8ms/step - loss: 188265.0781 - r_square: -0.0118 - val_loss: 182459.9219 - val_r_square: -0.0095\n",
      "Epoch 4/1000\n",
      "5858/5860 [============================>.] - ETA: 0s - loss: 187437.7812 - r_square: -0.0076\n",
      "Epoch 4: val_loss improved from 182459.92188 to 181770.82812, saving model to model.h5\n",
      "5860/5860 [==============================] - 49s 8ms/step - loss: 187470.8125 - r_square: -0.0076 - val_loss: 181770.8281 - val_r_square: -0.0057\n",
      "Epoch 5/1000\n",
      "5860/5860 [==============================] - ETA: 0s - loss: 186851.5000 - r_square: -0.0042\n",
      "Epoch 5: val_loss improved from 181770.82812 to 181167.09375, saving model to model.h5\n",
      "5860/5860 [==============================] - 48s 8ms/step - loss: 186851.5000 - r_square: -0.0042 - val_loss: 181167.0938 - val_r_square: -0.0023\n",
      "Epoch 6/1000\n",
      "5856/5860 [============================>.] - ETA: 0s - loss: 186235.9062 - r_square: -0.0012\n",
      "Epoch 6: val_loss improved from 181167.09375 to 180585.01562, saving model to model.h5\n",
      "5860/5860 [==============================] - 49s 8ms/step - loss: 186281.8906 - r_square: -0.0012 - val_loss: 180585.0156 - val_r_square: 9.0909e-04\n",
      "Epoch 7/1000\n",
      "5857/5860 [============================>.] - ETA: 0s - loss: 185806.8750 - r_square: 0.0017\n",
      "Epoch 7: val_loss improved from 180585.01562 to 180056.67188, saving model to model.h5\n",
      "5860/5860 [==============================] - 48s 8ms/step - loss: 185751.0469 - r_square: 0.0017 - val_loss: 180056.6719 - val_r_square: 0.0038\n",
      "Epoch 8/1000\n",
      "5858/5860 [============================>.] - ETA: 0s - loss: 185319.2031 - r_square: 0.0042\n",
      "Epoch 8: val_loss improved from 180056.67188 to 179636.18750, saving model to model.h5\n",
      "5860/5860 [==============================] - 48s 8ms/step - loss: 185283.8125 - r_square: 0.0042 - val_loss: 179636.1875 - val_r_square: 0.0062\n",
      "Epoch 9/1000\n",
      "4398/5860 [=====================>........] - ETA: 10s - loss: 183307.1875 - r_square: 0.0059"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 256, epochs=1000, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1, \n",
    "                    callbacks=callbacks\n",
    "                   )\n",
    "\n",
    "stop=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110c971-c179-4b2c-a855-ef8d80565abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72086d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Took {round(stop-start, 2)}s to run. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee55a97-28c2-4b1c-ab18-84cc4bdf9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    \n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_graphs(history, 'loss')\n",
    "    #plt.ylim(None, 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_graphs(history, 'r_square')\n",
    "    #plt.ylim(0, None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff2216-754e-408f-b8ed-7170ba649c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f959e9d-5c0c-47be-9d15-c3366b0155ca",
   "metadata": {},
   "source": [
    "### Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-france",
   "metadata": {},
   "source": [
    "Keras Tuner is the same idea as GridSearch, but in this case it is to try different NN designs to determine which one would be the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f50449-0a96-4aef-b016-5552237c3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "507dfbc9-765c-44eb-8fc9-8ca6b70b4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1158313-9173-4d91-8be1-7f05ae8c07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1. 1st Conv2D layer\n",
    "    if hp.Boolean(\"kernelRegularizer\"):\n",
    "        model.add(layers.Conv2D(hp.Int('conv1_units', min_value=32, max_value=1024, step=32),\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01),\n",
    "                                input_shape=(8, 8, NB_OHE)))\n",
    "    else:\n",
    "        model.add(layers.Conv2D(hp.Int('conv1_units', min_value=32, max_value=1024, step=32),\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation='relu',\n",
    "                                input_shape=(8, 8, NB_OHE)))\n",
    "\n",
    "    # 2.  MaxPool layer\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 3.  2nd Conv2D layer\n",
    "    model.add(layers.Conv2D(hp.Int('conv2_units', min_value=32, max_value=256, step=32),\n",
    "                            kernel_size=(3, 3),\n",
    "                            activation='relu'))\n",
    "\n",
    "    # 4.  Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # 5. BatchNormalization layer\n",
    "    if hp.Boolean(\"batchNormalization1\"):\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    # 6. Dropout layer\n",
    "    if hp.Boolean(\"dropout1\"):\n",
    "        dropout_rate = hp.Float(\"dropout_rate1\", min_value=0.2, max_value=0.5, step = 0.1)\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 7. 1st Dense layer\n",
    "    model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(\"units_dense1\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation_dense1\", [\"elu\", \"selu\", \"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 7. 2nd Dropout layer\n",
    "    if hp.Boolean(\"dropout2\"):\n",
    "        dropout_rate = hp.Float(\"dropout_rate2\", min_value=0.1, max_value=0.3, step = 0.1)\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 8. 2nd BatchNormalization layer\n",
    "    if hp.Boolean(\"batchNormalization2\"):\n",
    "        model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # 9. Tune the number of dense layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_dense{i+1}\", min_value=512, max_value=4096, step=128),\n",
    "                activation=hp.Choice(f\"activation_dense{i+1}\", [\"elu\", \"selu\", \"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 10. 3rd Dropout layer\n",
    "    if hp.Boolean(\"dropout3\"):\n",
    "        dropout_rate = hp.Float(\"dropout_rate3\", min_value=0.2, max_value=0.4, step = 0.1)\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 11. 3rd BatchNormalization layer\n",
    "    if hp.Boolean(\"batchNormalization3\"):\n",
    "        model.add(layers.BatchNormalization())         \n",
    "\n",
    "    # 12. Output layer\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    if hp.Boolean(\"lr_decay\"):\n",
    "        initial_learning_rate = 1e-2\n",
    "        decay_steps = 1000\n",
    "        decay_rate = 0.9\n",
    "        # Define the learning rate schedule\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate, decay_steps, decay_rate)\n",
    "    else:\n",
    "        lr_schedule = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[RSquare()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9839e53-1fe6-4d3c-973d-17c019bfc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    #max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"prediction_models\",\n",
    "    project_name=\"tuner_search_chess\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a11c7b7c-b213-4ecf-b1ba-6d75437e6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 14\n",
      "kernelRegularizer (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "conv1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': 'linear'}\n",
      "conv2_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "batchNormalization1 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "dropout1 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "units_dense1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_dense1 (Choice)\n",
      "{'default': 'elu', 'conditions': [], 'values': ['elu', 'selu', 'relu'], 'ordered': False}\n",
      "dropout2 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "batchNormalization2 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "dropout3 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "batchNormalization3 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr_decay (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8793ac6f-cbf3-4b15-a384-16fb669652b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, verbose=1)\n",
    "callbacks = [es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2cfce-f951-4920-bba9-6ea7ef3be416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |kernelRegularizer\n",
      "512               |512               |conv1_units\n",
      "160               |160               |conv2_units\n",
      "False             |False             |batchNormalization1\n",
      "False             |False             |dropout1\n",
      "64                |64                |units_dense1\n",
      "selu              |selu              |activation_dense1\n",
      "False             |False             |dropout2\n",
      "False             |False             |batchNormalization2\n",
      "1                 |1                 |num_layers\n",
      "True              |True              |dropout3\n",
      "True              |True              |batchNormalization3\n",
      "False             |False             |lr_decay\n",
      "0.00045197        |0.00045197        |lr\n",
      "0.2               |0.2               |dropout_rate3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 20:31:39.672821: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5197549056 exceeds 10% of free system memory.\n",
      "2023-06-30 20:31:42.922458: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5197549056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "211489/211489 [==============================] - 1851s 9ms/step - loss: 174308.2031 - r_square: 0.1000 - val_loss: 173277.8438 - val_r_square: 0.1185\n",
      "Epoch 2/30\n",
      "211489/211489 [==============================] - 1838s 9ms/step - loss: 169578.4688 - r_square: 0.1245 - val_loss: 167382.3281 - val_r_square: 0.1486\n",
      "Epoch 3/30\n",
      "211489/211489 [==============================] - 1837s 9ms/step - loss: 167866.7500 - r_square: 0.1335 - val_loss: 165721.1562 - val_r_square: 0.1572\n",
      "Epoch 4/30\n",
      "211489/211489 [==============================] - 1832s 9ms/step - loss: 165324.2344 - r_square: 0.1468 - val_loss: 172379.1719 - val_r_square: 0.1235\n",
      "Epoch 5/30\n",
      "140980/211489 [==================>...........] - ETA: 9:29 - loss: 163488.0469 - r_square: 0.1589"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=30, validation_data=(X_val, y_val))#, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3824dd2-8f90-4f78-8f84-a976fb046c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
