{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63691d6-e72f-49ea-9840-74ac8ac6cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install chess\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275661f0-d82b-4989-b5a9-9b7b0bb1657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import time\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "import chess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd355cc9-fcff-428a-98dc-4fb0244048c8",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6475230d-bcf5-44bb-95fd-e3a3213b5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run S3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511d03d8-42d9-4ff7-ad96-31a49f43b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#moves_df = pd.read_csv(\"../Data/moves_df.csv\")\n",
    "moves_df = open_csv(\"moves_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f911d60-9dac-4ee9-b598-1bc8b7789fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_index</th>\n",
       "      <th>moves</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>fen</th>\n",
       "      <th>zobrist_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e2e4</td>\n",
       "      <td>35</td>\n",
       "      <td>rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...</td>\n",
       "      <td>9384546495678726550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>e7e5</td>\n",
       "      <td>48</td>\n",
       "      <td>rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...</td>\n",
       "      <td>595762792459712928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>g1f3</td>\n",
       "      <td>111</td>\n",
       "      <td>rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQK...</td>\n",
       "      <td>15213300192948443293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>b8c6</td>\n",
       "      <td>47</td>\n",
       "      <td>r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNB...</td>\n",
       "      <td>8704797333742910878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>f1b5</td>\n",
       "      <td>52</td>\n",
       "      <td>r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/R...</td>\n",
       "      <td>5409798013178080797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023518</th>\n",
       "      <td>118318</td>\n",
       "      <td>a8c8</td>\n",
       "      <td>-6</td>\n",
       "      <td>2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP1BP1/1P1BPP1P...</td>\n",
       "      <td>13935396515866781493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023519</th>\n",
       "      <td>118318</td>\n",
       "      <td>f3g2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP2P1/1P1BPPBP/...</td>\n",
       "      <td>18028698229637126573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023520</th>\n",
       "      <td>118318</td>\n",
       "      <td>a7a6</td>\n",
       "      <td>12</td>\n",
       "      <td>2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...</td>\n",
       "      <td>2937820813377462641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023521</th>\n",
       "      <td>118318</td>\n",
       "      <td>a1c1</td>\n",
       "      <td>25</td>\n",
       "      <td>2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...</td>\n",
       "      <td>11978245410268853311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023522</th>\n",
       "      <td>118318</td>\n",
       "      <td>b7b5</td>\n",
       "      <td>5</td>\n",
       "      <td>2rq1rk1/4bppp/p1n1pn2/1p1p4/8/P1NP2P1/1P1BPPBP...</td>\n",
       "      <td>14285185648144582914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9023523 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         game_index moves  evaluation  \\\n",
       "0                 0  e2e4          35   \n",
       "1                 0  e7e5          48   \n",
       "2                 0  g1f3         111   \n",
       "3                 0  b8c6          47   \n",
       "4                 0  f1b5          52   \n",
       "...             ...   ...         ...   \n",
       "9023518      118318  a8c8          -6   \n",
       "9023519      118318  f3g2          -2   \n",
       "9023520      118318  a7a6          12   \n",
       "9023521      118318  a1c1          25   \n",
       "9023522      118318  b7b5           5   \n",
       "\n",
       "                                                       fen  \\\n",
       "0        rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR ...   \n",
       "1        rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBN...   \n",
       "2        rnbqkbnr/pppp1ppp/8/4p3/4P3/5N2/PPPP1PPP/RNBQK...   \n",
       "3        r1bqkbnr/pppp1ppp/2n5/4p3/4P3/5N2/PPPP1PPP/RNB...   \n",
       "4        r1bqkbnr/pppp1ppp/2n5/1B2p3/4P3/5N2/PPPP1PPP/R...   \n",
       "...                                                    ...   \n",
       "9023518  2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP1BP1/1P1BPP1P...   \n",
       "9023519  2rq1rk1/pp2bppp/2n1pn2/3p4/8/P1NP2P1/1P1BPPBP/...   \n",
       "9023520  2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...   \n",
       "9023521  2rq1rk1/1p2bppp/p1n1pn2/3p4/8/P1NP2P1/1P1BPPBP...   \n",
       "9023522  2rq1rk1/4bppp/p1n1pn2/1p1p4/8/P1NP2P1/1P1BPPBP...   \n",
       "\n",
       "                  zobrist_key  \n",
       "0         9384546495678726550  \n",
       "1          595762792459712928  \n",
       "2        15213300192948443293  \n",
       "3         8704797333742910878  \n",
       "4         5409798013178080797  \n",
       "...                       ...  \n",
       "9023518  13935396515866781493  \n",
       "9023519  18028698229637126573  \n",
       "9023520   2937820813377462641  \n",
       "9023521  11978245410268853311  \n",
       "9023522  14285185648144582914  \n",
       "\n",
       "[9023523 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moves_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bdda4-5217-4bde-91e4-f31eb3b6e6b4",
   "metadata": {},
   "source": [
    "# Create board representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec23eda-59da-4a2d-b295-147e97620fab",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d222413d-f742-433d-bc8f-291464edd87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OHE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50004998-23d6-47e4-8b2e-12332abbf76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_piece_index(piece):\n",
    "    #lowercase = black pieces\n",
    "    #uppercase = white pieces\n",
    "    if piece == \"P\":\n",
    "        return 0\n",
    "    if piece == \"N\":\n",
    "        return 1\n",
    "    if piece == \"B\":\n",
    "        return 2\n",
    "    if piece == \"R\":\n",
    "        return 3\n",
    "    if piece == \"Q\":\n",
    "        return 4\n",
    "    if piece == \"K\":\n",
    "        return 5\n",
    "\n",
    "    #is black_piece\n",
    "    return 6 + ohe_piece_index(piece.upper())\n",
    "\n",
    "def ohe_piece(piece):\n",
    "    ohe = [0]*12\n",
    "    index = ohe_piece_index(piece)\n",
    "    ohe[index] = 1\n",
    "    return ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13fa68ef-f374-435a-a7d1-eaff240c20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord(square):\n",
    "    row = 7 - square // 8\n",
    "    col = square % 8\n",
    "    return row, col\n",
    "\n",
    "def fen_to_matrix(fen):\n",
    "    matrix = np.zeros((8, 8, NB_OHE), dtype=np.uint8)\n",
    "    pieces = chess.Board(fen).piece_map()\n",
    "    for square in pieces.keys():\n",
    "        row, col = get_coord(square)\n",
    "        piece = pieces[square]\n",
    "        piece_symbol = piece.symbol()\n",
    "        matrix[row, col] = ohe_piece(piece_symbol)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bdf34e-2bda-4485-b4ae-8b649ecf17f6",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be169f2a-34d2-49d4-9f8f-924ff3466fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb2b509-468b-4217-80ac-3bc2f9a57378",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cpu_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1506b84-5bed-4a6a-b63e-5403c4325689",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we'll divide the fens into the nb of cpu cores we have, to use parallelize the creation of board representations\n",
    "\n",
    "def get_starting_indices(len_data, divide_into):\n",
    "    linspace = np.linspace(0, len_data, divide_into)\n",
    "    indices = [math.floor(x) for x in linspace]\n",
    "    return indices    \n",
    "\n",
    "def get_lengths(len_data, indices):\n",
    "    if len(indices) <= 1:\n",
    "        return [len_data]\n",
    "    lengths = [indices[1]]\n",
    "    for i in range(2, len(indices)):\n",
    "        lengths.append(indices[i]-indices[i-1])\n",
    "    lengths.append(len_data-indices[-1])\n",
    "    return lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e583c665-92c0-4e27-adaf-2456ff026a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_representations__subpart(all_fens, starting_index, length):\n",
    "    fens = all_fens[starting_index:starting_index+length]\n",
    "    X = np.zeros((len(fens), 8, 8, NB_OHE), dtype = np.uint8)\n",
    "    for i, fen in enumerate(fens):\n",
    "        X[i] = fen_to_matrix(fen)\n",
    "    return X\n",
    "\n",
    "def get_matrix_representations(df, total_size, divide_into=nb_cpu_cores):\n",
    "    X = np.zeros((total_size, 8, 8, NB_OHE), dtype = np.uint8)\n",
    "    fens = list(df.iloc[:total_size].fen)\n",
    "    \n",
    "    starting_indices = get_starting_indices(total_size, divide_into)\n",
    "    lengths = get_lengths(total_size, starting_indices)\n",
    "\n",
    "    with Pool() as pool:\n",
    "        async_results = [pool.apply_async(get_matrix_representations__subpart,\n",
    "                                        args = (fens.copy(), starting_indices[i], lengths[i])) for i in range(len(lengths))]\n",
    "\n",
    "        for i in range(len(async_results)):\n",
    "            start_index, length = starting_indices[i], lengths[i]\n",
    "            #sub_X = async_results[i].get()\n",
    "            X[start_index:start_index+length] = async_results[i].get()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b66e834f-563f-447a-ba03-a19ccae9aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_size = 4_000_000\n",
    "total_size = len(moves_df)\n",
    "fens = list(moves_df.fen)[:total_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62740399-e350-493f-b33a-41914a59cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating X took 4.0m, 32.280389070510864s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    X = get_matrix_representations(moves_df, total_size, divide_into=nb_cpu_cores)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Creating X took {(stop-start)//60}m, {(stop-start)%60}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c96745-9aed-41cf-9e90-a670cc648f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X takes up 1.03% of total memory\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import sys\n",
    "    \n",
    "total_memory = psutil.virtual_memory().total \n",
    "X_size = sys.getsizeof(X)\n",
    "print(f\"X takes up {round(100 * X_size/total_memory, 2)}% of total memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8e157-816c-4ca7-8247-c3fc3207c7c7",
   "metadata": {},
   "source": [
    "### Split into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c40fd9-73ce-4c9c-a372-0a39ae6fce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(moves_df.iloc[:total_size].evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18ddab86-d199-4731-b2e5-eab0f14cf759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test(dataX, dataY, train_ratio=0.75, validation_ratio=0.15, test_ratio=0.10):\n",
    "    if train_ratio+test_ratio+validation_ratio != 1:\n",
    "        print(\"Ratios do not add up to 1\")\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "        x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "        return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02998c37-744a-4e29-82e6-a63e367ca6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f35d32-853a-4152-9b42-f1645efd9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape : X_train -> (6767642, 8, 8, 12), y_train -> (6767642,)\n",
      "Validation set shape : X_val -> (1353528, 8, 8, 12), y_val -> (1353528,)\n",
      "Test set shape : X_test -> (902353, 8, 8, 12), y_train -> (902353,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set shape : X_train -> {X_train.shape}, y_train -> {y_train.shape}\")\n",
    "print(f\"Validation set shape : X_val -> {X_val.shape}, y_val -> {y_val.shape}\")\n",
    "print(f\"Test set shape : X_test -> {X_test.shape}, y_train -> {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdde28-8cfa-48b6-b46a-7ce170059de0",
   "metadata": {},
   "source": [
    "# Try Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcb33da9-763b-44de-9e96-8ccb428bab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 16:39:42.128684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-30 16:39:43.603744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.12.0\n",
      "Eager mode:  True\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #remove warnings caused by tensorflow\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b16cbf0-53ad-422d-9c87-5a00b7bf30a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 16:39:45.420509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13545 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:af:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(1024, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(8, 8, NB_OHE)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(2048, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3e79383-cdfd-469b-b924-b469c639119e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 6, 6, 1024)        111616    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 1024)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 1, 1, 512)         4719104   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              1050624   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,036,801\n",
      "Trainable params: 9,033,729\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model.build(X_train_us.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "085f1493-f214-4732-8015-68fb96bd8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 1e-2\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "\n",
    "# Define the learning rate schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "          optimizer=tf.keras.optimizers.Adam(\n",
    "              #learning_rate=lr_schedule\n",
    "              learning_rate = 1e-4\n",
    "          ),\n",
    "          metrics=[RSquare()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0b5dd5b-1f6f-4452-95b9-c7c69941d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=8, verbose=1)\n",
    "\n",
    "callbacks = [es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3e023dc-50ce-4106-bf1b-cbb5c33daa8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 06:57:01.575536: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5197549056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13219/13219 [==============================] - 425s 32ms/step - loss: 171127.0156 - r_square: 0.1136 - val_loss: 179341.8438 - val_r_square: 0.1084\n",
      "Epoch 2/100\n",
      "13219/13219 [==============================] - 416s 31ms/step - loss: 156435.6875 - r_square: 0.1897 - val_loss: 203827.7500 - val_r_square: -0.0133\n",
      "Epoch 3/100\n",
      "13219/13219 [==============================] - 414s 31ms/step - loss: 145356.2969 - r_square: 0.2471 - val_loss: 175813.7031 - val_r_square: 0.1259\n",
      "Epoch 4/100\n",
      "13219/13219 [==============================] - 412s 31ms/step - loss: 137159.3438 - r_square: 0.2896 - val_loss: 200421.3906 - val_r_square: 0.0036\n",
      "Epoch 5/100\n",
      "13219/13219 [==============================] - 415s 31ms/step - loss: 130468.6562 - r_square: 0.3242 - val_loss: 237130.5625 - val_r_square: -0.1789\n",
      "Epoch 6/100\n",
      "13219/13219 [==============================] - 413s 31ms/step - loss: 124628.5938 - r_square: 0.3545 - val_loss: 177585.0312 - val_r_square: 0.1171\n",
      "Epoch 7/100\n",
      "13219/13219 [==============================] - 413s 31ms/step - loss: 119305.1172 - r_square: 0.3821 - val_loss: 165836.2188 - val_r_square: 0.1755\n",
      "Epoch 8/100\n",
      "13219/13219 [==============================] - 415s 31ms/step - loss: 114585.5859 - r_square: 0.4065 - val_loss: 166672.5938 - val_r_square: 0.1714\n",
      "Epoch 9/100\n",
      "13219/13219 [==============================] - 413s 31ms/step - loss: 111963.1094 - r_square: 0.4201 - val_loss: 154392.3906 - val_r_square: 0.2324\n",
      "Epoch 10/100\n",
      "13219/13219 [==============================] - 414s 31ms/step - loss: 108592.5234 - r_square: 0.4376 - val_loss: 159116.6094 - val_r_square: 0.2090\n",
      "Epoch 11/100\n",
      "13219/13219 [==============================] - 414s 31ms/step - loss: 105572.6328 - r_square: 0.4532 - val_loss: 154446.1719 - val_r_square: 0.2322\n",
      "Epoch 12/100\n",
      " 3587/13219 [=======>......................] - ETA: 4:48 - loss: 102905.8359 - r_square: 0.4633"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m#callbacks=callbacks\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m stop\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/engine/training.py:1691\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1690\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1691\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/utils/tf_utils.py:680\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/keras/utils/tf_utils.py:673\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 673\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1126\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1125\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 512, epochs=100, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1, \n",
    "                    #callbacks=callbacks\n",
    "                   )\n",
    "\n",
    "stop=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72086d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 272.28s to run. \n"
     ]
    }
   ],
   "source": [
    "print(f\"Took {round(stop-start, 2)}s to run. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bee55a97-28c2-4b1c-ab18-84cc4bdf9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    \n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_graphs(history, 'loss')\n",
    "    #plt.ylim(None, 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_graphs(history, 'r_square')\n",
    "    #plt.ylim(0, None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff2216-754e-408f-b8ed-7170ba649c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f959e9d-5c0c-47be-9d15-c3366b0155ca",
   "metadata": {},
   "source": [
    "### Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-france",
   "metadata": {},
   "source": [
    "Keras Tuner is the same idea as GridSearch, but in this case it is to try different NN designs to determine which one would be the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41f50449-0a96-4aef-b016-5552237c3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture capt\n",
    "!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "507dfbc9-765c-44eb-8fc9-8ca6b70b4f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1158313-9173-4d91-8be1-7f05ae8c07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1. 1st Conv2D layer\n",
    "    if hp.Boolean(\"kernelRegularizer\"):\n",
    "        model.add(layers.Conv2D(hp.Int('conv1_units', min_value=32, max_value=1024, step=32),\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=regularizers.l2(0.01),\n",
    "                                input_shape=(8, 8, NB_OHE)))\n",
    "    else:\n",
    "        model.add(layers.Conv2D(hp.Int('conv1_units', min_value=32, max_value=1024, step=32),\n",
    "                                kernel_size=(3, 3),\n",
    "                                activation='relu',\n",
    "                                input_shape=(8, 8, NB_OHE)))\n",
    "\n",
    "    # 2.  MaxPool layer\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 3.  2nd Conv2D layer\n",
    "    model.add(layers.Conv2D(hp.Int('conv2_units', min_value=32, max_value=256, step=32),\n",
    "                            kernel_size=(3, 3),\n",
    "                            activation='relu'))\n",
    "\n",
    "    # 4.  Flatten layer\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # 5. BatchNormalization layer\n",
    "    if hp.Boolean(\"batchNormalization1\"):\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    # 6. Dropout layer\n",
    "    if hp.Boolean(\"dropout1\"):\n",
    "        dropout_rate = hp.Float(\"dropout_rate1\", min_value=0.2, max_value=0.5, step = 0.1)\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 7. 1st Dense layer\n",
    "    model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(\"units_dense1\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation_dense1\", [\"elu\", \"selu\", \"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 7. 2nd Dropout layer\n",
    "    if hp.Boolean(\"dropout2\"):\n",
    "        dropout_rate = hp.Float(\"dropout_rate2\", min_value=0.1, max_value=0.3, step = 0.1)\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 8. 2nd BatchNormalization layer\n",
    "    if hp.Boolean(\"batchNormalization2\"):\n",
    "        model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # 9. Tune the number of dense layers\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_dense{i+1}\", min_value=512, max_value=4096, step=128),\n",
    "                activation=hp.Choice(f\"activation_dense{i+1}\", [\"elu\", \"selu\", \"relu\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 10. 3rd Dropout layer\n",
    "    if hp.Boolean(\"dropout3\"):\n",
    "        dropout_rate = hp.Float(\"dropout_rate3\", min_value=0.2, max_value=0.4, step = 0.1)\n",
    "        model.add(layers.Dropout(rate=dropout_rate))\n",
    "\n",
    "    # 11. 3rd BatchNormalization layer\n",
    "    if hp.Boolean(\"batchNormalization3\"):\n",
    "        model.add(layers.BatchNormalization())         \n",
    "\n",
    "    # 12. Output layer\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    if hp.Boolean(\"lr_decay\"):\n",
    "        initial_learning_rate = 1e-2\n",
    "        decay_steps = 1000\n",
    "        decay_rate = 0.9\n",
    "        # Define the learning rate schedule\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate, decay_steps, decay_rate)\n",
    "    else:\n",
    "        lr_schedule = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[RSquare()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9839e53-1fe6-4d3c-973d-17c019bfc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    #max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"prediction_models\",\n",
    "    project_name=\"tuner_search_chess\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a11c7b7c-b213-4ecf-b1ba-6d75437e6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 14\n",
      "kernelRegularizer (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "conv1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': 'linear'}\n",
      "conv2_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "batchNormalization1 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "dropout1 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "units_dense1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "activation_dense1 (Choice)\n",
      "{'default': 'elu', 'conditions': [], 'values': ['elu', 'selu', 'relu'], 'ordered': False}\n",
      "dropout2 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "batchNormalization2 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "dropout3 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "batchNormalization3 (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr_decay (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8793ac6f-cbf3-4b15-a384-16fb669652b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, verbose=1)\n",
    "callbacks = [es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2cfce-f951-4920-bba9-6ea7ef3be416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |kernelRegularizer\n",
      "512               |512               |conv1_units\n",
      "160               |160               |conv2_units\n",
      "False             |False             |batchNormalization1\n",
      "False             |False             |dropout1\n",
      "64                |64                |units_dense1\n",
      "selu              |selu              |activation_dense1\n",
      "False             |False             |dropout2\n",
      "False             |False             |batchNormalization2\n",
      "1                 |1                 |num_layers\n",
      "True              |True              |dropout3\n",
      "True              |True              |batchNormalization3\n",
      "False             |False             |lr_decay\n",
      "0.00045197        |0.00045197        |lr\n",
      "0.2               |0.2               |dropout_rate3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 20:31:39.672821: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5197549056 exceeds 10% of free system memory.\n",
      "2023-06-30 20:31:42.922458: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5197549056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "211489/211489 [==============================] - 1851s 9ms/step - loss: 174308.2031 - r_square: 0.1000 - val_loss: 173277.8438 - val_r_square: 0.1185\n",
      "Epoch 2/30\n",
      "211489/211489 [==============================] - 1838s 9ms/step - loss: 169578.4688 - r_square: 0.1245 - val_loss: 167382.3281 - val_r_square: 0.1486\n",
      "Epoch 3/30\n",
      "211489/211489 [==============================] - 1837s 9ms/step - loss: 167866.7500 - r_square: 0.1335 - val_loss: 165721.1562 - val_r_square: 0.1572\n",
      "Epoch 4/30\n",
      "211489/211489 [==============================] - 1832s 9ms/step - loss: 165324.2344 - r_square: 0.1468 - val_loss: 172379.1719 - val_r_square: 0.1235\n",
      "Epoch 5/30\n",
      "140980/211489 [==================>...........] - ETA: 9:29 - loss: 163488.0469 - r_square: 0.1589"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=30, validation_data=(X_val, y_val))#, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3824dd2-8f90-4f78-8f84-a976fb046c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
